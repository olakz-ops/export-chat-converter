#!/usr/bin/env node

// Test the actual application with real sample data
import { readFileSync, writeFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join } from 'path';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

console.log('ğŸ§ª Testing REAL APPLICATION with sample data...\n');

try {
    // Import actual application modules
    const { parseChatContent } = await import('./js/core/parser.js?v=12');
    const { generateHTMLOutput } = await import('./js/utils/htmlGenerator.js?v=12');
    
    console.log('âœ… Application modules loaded');
    
    // Load real sample data
    const sampleDir = join(__dirname, 'sample');
    const chatPath = join(sampleDir, '_chat.txt');
    
    console.log('ğŸ“„ Loading real chat file...');
    const chatContent = readFileSync(chatPath, 'utf8');
    
    console.log('ğŸ” Parsing with real parser...');
    const messages = parseChatContent(chatContent);
    console.log(`âœ… Parsed ${messages.length} messages`);
    
    // Load real audio files
    console.log('ğŸµ Loading real audio files...');
    const audioFiles = [
        '00000007-AUDIO-2025-06-11-12-24-05.opus',
        '00000015-AUDIO-2025-06-11-12-34-39.opus', 
        '00000026-AUDIO-2025-06-11-18-55-07.opus'
    ];
    
    const mediaFiles = new Map();
    audioFiles.forEach(filename => {
        const filePath = join(sampleDir, filename);
        try {
            const fileBuffer = readFileSync(filePath);
            // Create a File-like object for the application
            const file = {
                name: filename,
                type: 'audio/opus',
                size: fileBuffer.length,
                arrayBuffer: () => Promise.resolve(fileBuffer.buffer),
                // Add stream method for FileReader compatibility
                stream: () => new ReadableStream({
                    start(controller) {
                        controller.enqueue(new Uint8Array(fileBuffer));
                        controller.close();
                    }
                })
            };
            mediaFiles.set(filename, file);
            console.log(`  âœ… Loaded ${filename} (${fileBuffer.length} bytes)`);
        } catch (error) {
            console.log(`  âŒ Failed to load ${filename}:`, error.message);
        }
    });
    
    // Process messages with real audio file matching
    console.log('ğŸ”— Matching audio files to messages...');
    const processedMessages = messages.map((message, index) => {
        // Check if message has audio attachment
        const audioMatch = message.text.match(/â€<××¦×•×¨×£: (.*?\\.(opus|mp3))>/);
        if (audioMatch) {
            const filename = audioMatch[1];
            console.log(`  ğŸ“ Message ${index}: Found audio "${filename}"`);
            
            if (mediaFiles.has(filename)) {
                console.log(`    âœ… Audio file found: ${filename}`);
                
                // Add simulated transcription for testing (since we don't have real OpenAI API)
                const transcriptions = {
                    '00000007-AUDIO-2025-06-11-12-24-05.opus': '×©×œ×•× ×¨×¤××œ, ××™×š ××ª×”? ×× ×™ ××ª×§×©×¨ ×œ×’×‘×™ ×”××›×©×™×¨ ×ª×“×¨×™× ×©×“×™×‘×¨× ×• ×¢×œ×™×•. ××¤×©×¨ ×œ×§×‘×œ ×¤×¨×˜×™× × ×•×¡×¤×™×?',
                    '00000015-AUDIO-2025-06-11-12-34-39.opus': '×›×Ÿ ×‘×˜×—, ×”××—×™×¨ ×”×•× 500 ×©×§×œ ×•×”××©×œ×•×— ×—×™× × ×œ×›×œ ×”××¨×¥. ×”××›×©×™×¨ ××’×™×¢ ×¢× ××—×¨×™×•×ª ×©×œ ×©× ×”.',
                    '00000026-AUDIO-2025-06-11-18-55-07.opus': '××•×©×œ×, ×× ×™ ××¢×•× ×™×™×Ÿ ×œ×§× ×•×ª. ××¤×©×¨ ×œ×©×œ× ×‘××©×¨××™? ×•××ª×™ ×–×” ×™×’×™×¢?'
                };
                
                return {
                    ...message,
                    text: transcriptions[filename] || '[×ª××œ×•×œ ×œ× ×–××™×Ÿ]',
                    audioFile: filename,
                    transcriptionCost: 0.0156,
                    originalAudio: mediaFiles.get(filename)
                };
            } else {
                console.log(`    âŒ Audio file missing: ${filename}`);
                return {
                    ...message,
                    audioFile: filename,
                    transcriptionCost: 0,
                    originalAudio: null
                };
            }
        }
        return message;
    });
    
    // Calculate total cost
    const totalCost = processedMessages.reduce((sum, msg) => sum + (msg.transcriptionCost || 0), 0);
    console.log(`ğŸ’° Total transcription cost: $${totalCost.toFixed(4)}`);
    
    // Generate HTML using real application module
    console.log('ğŸ“„ Generating HTML with real application module...');
    const html = await generateHTMLOutput(processedMessages, totalCost);
    
    // Write to output file
    const outputPath = join(__dirname, 'real-application-test.html');
    writeFileSync(outputPath, html);
    
    console.log(`\\nâœ… REAL APPLICATION TEST COMPLETED!`);
    console.log(`ğŸ“„ Generated: ${outputPath}`);
    console.log(`ğŸ“Š HTML size: ${(html.length / 1024).toFixed(1)} KB`);
    console.log(`ğŸµ Audio messages with transcriptions: ${processedMessages.filter(m => m.audioFile && m.transcriptionCost > 0).length}`);
    console.log(`ğŸ’° Total cost: $${totalCost.toFixed(4)}`);
    console.log(`\\nğŸŒ Open in browser: http://localhost:8001/real-application-test.html`);
    
} catch (error) {
    console.error('âŒ Test failed:', error.message);
    console.error('Stack:', error.stack);
}